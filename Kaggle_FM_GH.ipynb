{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movielens-fds/training.csv\n",
      "movielens-fds/test.csv\n",
      "movielens-fds/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pylab as plt\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('movielens-fds'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predict_f,data_test):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = np.array([predict_f(u,i) for (u,i) in ids_to_estimate ])\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "\n",
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "## Divide the data in two sets: training and test\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.05)),\n",
    "                                   replace=False)\n",
    "    df['for_testing'] = False\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(user_id, movie_id, dummie_idx_users, dummie_idx_movies, N_dummies):\n",
    "    hot_user = dummie_idx_users[user_id] ; hot_movie = dummie_idx_movies[movie_id]\n",
    "    x = np.zeros(N_dummies)\n",
    "    x[hot_user] = 1 ; x[hot_movie] = 1 \n",
    "    return x\n",
    "\n",
    "def evaluate2(predict_f, data_test, users_index, movies_index, mean_rating, dummie_idx_users, dummie_idx_movies,N_dummies):\n",
    "    \n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = []\n",
    "    \n",
    "    for u,i in ids_to_estimate:\n",
    "        if u not in users_index and i in movies_index:\n",
    "            estimated.append(3)\n",
    "        \n",
    "        if u in users_index and i in movies_index:\n",
    "            x = get_x_2(u,i,dummie_idx_users,dummie_idx_movies,N_dummies)\n",
    "            estimated.append(predict_f(x))\n",
    "            \n",
    "        if i not in movies_index:\n",
    "            estimated.append(mean_rating) # this is a new movie\n",
    "\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./movielens-fds/training.csv')\n",
    "df.head()\n",
    "\n",
    "grouped    = df.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "df_train = df[grouped.for_testing == False]\n",
    "df_val   = df[grouped.for_testing == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys_fm4():\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "\n",
    "    def __init__(self,df_train,df_val, num_components=10):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.df_train       = df_train\n",
    "        self.df_val         = df_val\n",
    "        self.num_components = num_components\n",
    "        self.train          = pd.pivot_table(self.df_train[['user_id','movie_id','rating']],columns='movie_id',index='user_id',values='rating')\n",
    "        # We create a dictionary where we will store the user_id and movie_id which correspond \n",
    "        # to each index in the Rating matrix\n",
    "        self.N_users  = len(self.train.index) \n",
    "        self.N_movies = len(self.train.columns)\n",
    "        self.N_samples = len(self.df_train)\n",
    "        self.N_dummies = self.N_users + self.N_movies  \n",
    "        self.users_index  = set(self.df_train.user_id)\n",
    "        self.movies_index = set(self.df_train.movie_id)\n",
    "        self.dummie_idx_users  = dict(zip(self.users_index, range(self.N_users)))\n",
    "        self.dummie_idx_movies = dict(zip(self.movies_index, range(self.N_users,self.N_users+self.N_movies)))\n",
    "        \n",
    "    def __sdg__(self):\n",
    "        l = []\n",
    "        for idx in self.training_indices:\n",
    "            l.append(idx)\n",
    "            if len(l)%1000 == 0: print('Wait {} idxs'.format(len(self.training_indices)-len(l)))\n",
    "            y     = np.array(self.df_train.iloc[idx,3]) \n",
    "            user  = self.df_train.iloc[idx,:].user_id\n",
    "            movie = self.df_train.iloc[idx,:].movie_id\n",
    "            x     = get_x(user, movie, self.dummie_idx_users, self.dummie_idx_movies, self.N_dummies)\n",
    "            \n",
    "            prediction = self.predict(x)\n",
    "            loss_derivative = 2*(prediction-y)\n",
    "            #Update w0\n",
    "            grad_w0 = loss_derivative\n",
    "            self.w0 = self.w0 - self.learn_rate * (grad_w0 + 2*self.lmbda * self.w0)\n",
    "\n",
    "            for i in x.nonzero():\n",
    "                grad_w = loss_derivative * x[i]\n",
    "                self.w[i] = self.w[i] - self.learn_rate*(grad_w + 2*self.lmbda*self.w[i])\n",
    "\n",
    "                for f in range(self.num_components):\n",
    "                    grad_V = loss_derivative*x[i]*(sum(x*self.V[:, f]) - x[i]*self.V[i, f])\n",
    "                    self.V[i, f] = self.V[i, f] - self.learn_rate * (grad_V + 2*self.lmbda*self.V[i, f])\n",
    "            \n",
    "    def fit(self,n_epochs = 1,learning_rate =0.01,lmbda=0.1,verbose =True):\n",
    "        \"\"\" We decompose the R matrix into to submatrices using the training data \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.learn_rate = learning_rate\n",
    "        self.lmbda = lmbda\n",
    "        \n",
    "        self.ratings = np.float32(self.train.fillna(0).values)\n",
    "        self.mean_rating = self.ratings[self.ratings>0].mean() \n",
    "        self.train_rmse =[]\n",
    "        self.test_rmse = []\n",
    "        iter_diff = 0\n",
    "        \n",
    "        # initialize model parameters\n",
    "        self.w0 = self.mean_rating\n",
    "        self.w  = np.random.normal(scale=1./self.N_dummies, size=self.N_dummies)\n",
    "        self.V  = np.random.normal(scale=1./self.num_components, size=(self.N_dummies, self.num_components))\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            print('Epoch: {}'.format(epoch))\n",
    "            \n",
    "            self.training_indices = np.arange(self.N_samples)\n",
    "            \n",
    "            #shuffle training samples\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            self.__sdg__()\n",
    "            \n",
    "            self.train_rmse.append(evaluate2(self.predict,self.df_train, self.users_index, self.movies_index, self.mean_rating, self.dummie_idx_users, self.dummie_idx_movies,self.N_dummies))\n",
    "            self.test_rmse.append(evaluate2(self.predict,self.df_val, self.users_index, self.movies_index, self.mean_rating, self.dummie_idx_users, self.dummie_idx_movies,self.N_dummies))\n",
    "            \n",
    "            print('\\tTrain rmse: %s' % self.train_rmse[-1])\n",
    "            print('\\tTest rmse: %s' % self.test_rmse[-1])\n",
    "            \n",
    "        if(self.verbose):\n",
    "            self.__plot_learning_curves__()\n",
    "    \n",
    "    def __plot_learning_curves__(self):\n",
    "        plt.plot(self.train_rmse,'--o',label=\"train_error\")\n",
    "        plt.plot(self.test_rmse,'--o',label=\"test_error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\" Single user and item prediction.\"\"\"\n",
    "        (i, j) = x.nonzero()[0]\n",
    "        interact = sum((reco.V[i,:]*x[i] + reco.V[j,:]*x[j])**2 - ((reco.V[i,:]**2)*x[i]**2 + (reco.V[j,:]**2)*x[j]**2))/2\n",
    "        return reco.w0 + reco.w[i]*x[i] + reco.w[j]*x[j] + interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_red = df_train[df_train.user_id < 1000] \n",
    "df_val_red = df_val[df_val.user_id < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = RecSys_fm4(df_train_red,df_val_red,num_components=5)\n",
    "reco.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
