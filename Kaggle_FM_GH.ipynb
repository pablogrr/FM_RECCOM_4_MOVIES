{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>FACTORIZATION MACHINES</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movielens-fds/training.csv\n",
      "movielens-fds/test.csv\n",
      "movielens-fds/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pylab as plt\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('movielens-fds'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predict_f,data_test):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = np.array([predict_f(u,i) for (u,i) in ids_to_estimate ])\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "\n",
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "## Divide the data in two sets: training and test\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.05)),\n",
    "                                   replace=False)\n",
    "    df['for_testing'] = False\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to implement my code for FM I built a get_x() function: a function that takes as input (user_id, movie_id) and gives as output a sparse vector $X=(0,..,1,0,...,1,..) \\in R^P$, where $P$ are the dimensions N_dummies, given by the one hot encode of the training data: the ones are in the positions $i$ and $j$, and $i$ maps the users and $j$ the movies. I.e. P=N_users + N_movies (I will add extra features in a second step). \n",
    "\n",
    "I also updated the evaluate function, that is always based on a RMSE metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(user_id, movie_id, dummie_idx_users, dummie_idx_movies, N_dummies):\n",
    "    hot_user = dummie_idx_users[user_id] ; hot_movie = dummie_idx_movies[movie_id]\n",
    "    row = np.array([0,0]) ; col = np.array([hot_user,hot_movie]) ; data = np.array([1, 1]) \n",
    "    x = csr_matrix((data, (row, col)), shape=(1, N_dummies))\n",
    "    return x\n",
    "\n",
    "def evaluate2(predict_f, data_test, users_index, movies_index, mean_rating, dummie_idx_users, dummie_idx_movies, N_dummies):\n",
    "    \n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = []\n",
    "    \n",
    "    for u,i in ids_to_estimate:\n",
    "        if u not in users_index and i in movies_index:\n",
    "            estimated.append(3)\n",
    "        \n",
    "        if u in users_index and i in movies_index:\n",
    "            x = get_x(u,i,dummie_idx_users,dummie_idx_movies,N_dummies)\n",
    "            estimated.append(predict_f(x))\n",
    "            \n",
    "        if i not in movies_index:\n",
    "            estimated.append(mean_rating) # this is a new movie\n",
    "\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./movielens-fds/training.csv')\n",
    "df.head()\n",
    "\n",
    "grouped    = df.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "df_train = df[grouped.for_testing == False]\n",
    "df_val   = df[grouped.for_testing == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here the model: is based on the logic we used in class for the Vanilla one and on the equations from the original paper \"Factorization Machines - Steffen Rendle - Osaka University, 2010\".\n",
    "\n",
    "For the predict part I took advantage of the reformulation of the interaction part, that has only linear complexity $O(KN)$, where K is the dimension of the latent space, our parameter \"num_components\", and N of the vector $X$:\n",
    "\n",
    "$$\n",
    "\\frac{1}{2} \\sum_{f=1}^K [(\\sum_{i=1}^N V_{i,f} x_i)^2 - \\sum_{i=1}^N V_{i,f}^2 x_i^2)]\n",
    "$$\n",
    "\n",
    "The components of the gradient in the SGD are $\\frac{\\partial L}{\\partial \\theta} = \\frac{\\partial L}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial \\theta}$. \n",
    "\n",
    "Where: \n",
    "\n",
    "$\\frac{\\partial \\hat y}{\\partial \\theta} = 1 ,\\; \\;$ if $\\theta = w_0$ \n",
    "\n",
    "$\\frac{\\partial \\hat y}{\\partial \\theta} = x_i,\\; \\;$ if $\\theta = w_i$ \n",
    "\n",
    "$\\frac{\\partial \\hat y}{\\partial \\theta} = x_i[\\sum_1^N V_{j,f} x_j - V_{i,f} x_i],\\; \\;$ if $\\theta = V_{i,f}$.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys_fm():\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "\n",
    "    def __init__(self,df_train,df_val, num_components=10):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.df_train       = df_train\n",
    "        self.df_val         = df_val\n",
    "        \n",
    "        self.num_components = num_components\n",
    "        self.N_samples = len(self.df_train)\n",
    "        self.users_index  = set(self.df_train.user_id)\n",
    "        self.movies_index = set(self.df_train.movie_id)\n",
    "        self.N_users      = len(self.users_index) \n",
    "        self.N_movies     = len(self.movies_index)\n",
    "        self.N_dummies = self.N_users + self.N_movies \n",
    "        #Dictionaries where I store the corrispondence between user_id, movie_id and their position \n",
    "        #in a one-hot-encode matrix.\n",
    "        self.dummie_idx_users  = dict(zip(self.users_index, range(self.N_users)))\n",
    "        self.dummie_idx_movies = dict(zip(self.movies_index, range(self.N_users,self.N_users+self.N_movies)))\n",
    "        \n",
    "    def __sdg__(self):\n",
    "        l = []\n",
    "        for idx in self.training_indices:\n",
    "            l.append(idx)\n",
    "            if len(l)%1000 == 0: print('Wait {} idxs'.format(len(self.training_indices)-len(l)))\n",
    "            y     = np.array(self.df_train.iloc[idx,3]) \n",
    "            user  = self.df_train.iloc[idx,:].user_id\n",
    "            movie = self.df_train.iloc[idx,:].movie_id\n",
    "            x     = get_x(user, movie, self.dummie_idx_users, self.dummie_idx_movies, self.N_dummies)\n",
    "            \n",
    "            prediction = self.predict(x)\n",
    "            #the base derivative to evaluate each gradient\n",
    "            loss_derivative = 2*(prediction-y)\n",
    "            #Update w0\n",
    "            grad_w0 = loss_derivative\n",
    "            self.w0 = self.w0 - self.learn_rate * (grad_w0 + 2*self.lmbda * self.w0)\n",
    "            #Update w and V just using non zero values\n",
    "            for i in x.indices:\n",
    "                grad_w = loss_derivative * x[0,i]\n",
    "                self.w[i] = self.w[i] - self.learn_rate*(grad_w + 2*self.lmbda*self.w[i])\n",
    "\n",
    "                for f in range(self.num_components):\n",
    "                    grad_V = loss_derivative*x[0,i]*(sum(x*self.V[:, f]) - x[0,i]*self.V[i, f])\n",
    "                    self.V[i, f] = self.V[i, f] - self.learn_rate * (grad_V + 2*self.lmbda*self.V[i, f])\n",
    "            \n",
    "    def fit(self,n_epochs = 10,learning_rate =0.01,lmbda=0.1,verbose =True):\n",
    "        \"\"\" We decompose the R matrix into to submatrices using the training data \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.learn_rate = learning_rate\n",
    "        self.lmbda = lmbda\n",
    "        \n",
    "        self.mean_rating = self.df_train.rating.mean() \n",
    "        self.train_rmse =[]\n",
    "        self.test_rmse = []\n",
    "        iter_diff = 0\n",
    "        \n",
    "        # initialize model parameters\n",
    "        self.w0 = self.mean_rating\n",
    "        self.w  = np.random.normal(scale=1./self.N_dummies, size=self.N_dummies)\n",
    "        self.V  = np.random.normal(scale=1./self.num_components, size=(self.N_dummies, self.num_components))\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            print('Epoch: {}'.format(epoch))\n",
    "            \n",
    "            self.training_indices = np.arange(self.N_samples)\n",
    "            \n",
    "            #shuffle training samples\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            self.__sdg__()\n",
    "            \n",
    "            self.train_rmse.append(evaluate2(self.predict,self.df_train, self.users_index, self.movies_index, self.mean_rating, self.dummie_idx_users, self.dummie_idx_movies,self.N_dummies))\n",
    "            self.test_rmse.append(evaluate2(self.predict,self.df_val, self.users_index, self.movies_index, self.mean_rating, self.dummie_idx_users, self.dummie_idx_movies,self.N_dummies))\n",
    "            \n",
    "            print('\\tTrain rmse: %s' % self.train_rmse[-1])\n",
    "            print('\\tTest rmse: %s' % self.test_rmse[-1])\n",
    "            \n",
    "        if(self.verbose):\n",
    "            self.__plot_learning_curves__()\n",
    "    \n",
    "    def __plot_learning_curves__(self):\n",
    "        plt.plot(self.train_rmse,'--o',label=\"train_error\")\n",
    "        plt.plot(self.test_rmse,'--o',label=\"test_error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\" Single x prediction.\"\"\"\n",
    "        #Predicting y from a sparse x using just non zero values.\n",
    "        sx = 0 ; dx = 0 ; linear = 0\n",
    "        \n",
    "        for i in x.indices:\n",
    "            sx += self.V[i,:]*x[0,i]\n",
    "            dx += (self.V[i,:]**2)*x[0,i]**2\n",
    "            linear += self.w[i]*x[0,i]\n",
    "    \n",
    "        interact  = sum(sx**2 - dx)/2 \n",
    "\n",
    "        return self.w0 + linear + interact\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_red = df_train[df_train.user_id < 10] \n",
    "df_val_red = df_val[df_val.user_id < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco = RecSys_fm4(df_train,df_val,num_components=5)\n",
    "#reco.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried the to add implicit features, for instance the \"genre\". In order to do that I will stack at the bottom of the vector $x$ a one-hot-encode of the genre associated to each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>IMAX</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Action  Adventure  Animation  Children  Comedy  Crime  Documentary  \\\n",
       "0         0          0          0         0       0      0            0   \n",
       "305       0          0          0         0       0      0            0   \n",
       "540       0          0          0         0       1      0            0   \n",
       "742       0          0          0         0       1      0            0   \n",
       "957       0          0          0         0       1      0            0   \n",
       "\n",
       "     Drama  Fantasy  Film-Noir  Horror  IMAX  Musical  Mystery  Romance  \\\n",
       "0        1        0          0       0     0        0        0        0   \n",
       "305      1        0          0       0     0        0        0        0   \n",
       "540      0        0          0       0     0        0        0        0   \n",
       "742      0        0          0       0     0        0        0        1   \n",
       "957      0        0          0       0     0        0        0        0   \n",
       "\n",
       "     Sci-Fi  Thriller  War  Western  movie_id  \n",
       "0         0         0    0        0       307  \n",
       "305       0         1    0        0       481  \n",
       "540       0         0    0        0      1091  \n",
       "742       0         0    0        0      1257  \n",
       "957       0         0    0        0      1449  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummie_genre = reco.df_train['genre'].str.get_dummies(sep=\"|\")\n",
    "dummie_genre = pd.concat([dummie_genre, reco.df_train['movie_id']],axis=1).drop_duplicates().drop(['(no genres listed)'], axis=1)\n",
    "dummie_genre.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the dictionary that maps each movie to the positions of one in the \"last part of vector\" $x$ associated with the movie genre of the observation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2genre = dict(zip(dummie_genre.columns[:-1], range(len(dummie_genre.columns[:-1]))))\n",
    "movie2genre = {}\n",
    "\n",
    "for i in range(len(dummie_genre)):\n",
    "    movie2genre[dummie_genre.iloc[i,-1]] = np.array(dummie_genre.iloc[i,:-1]).nonzero()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x2(user_id, movie_id, dummie_idx_users, dummie_idx_movies, dummie_idx_genre, N_dummies):\n",
    "    hot_user = dummie_idx_users[user_id] ; hot_movie = dummie_idx_movies[movie_id]\n",
    "    row = np.zeros(2+len(dummie_idx_genre[movie_id]))\n",
    "    col = np.r_[np.array([hot_user,hot_movie]),dummie_idx_genre[movie_id]] \n",
    "    data = np.ones(2+len(dummie_idx_genre[movie_id])) \n",
    "    x = csr_matrix((data, (row, col)), shape=(1, N_dummies))\n",
    "    return x\n",
    "\n",
    "def evaluate3(predict_f, data_test, users_index, \n",
    "              movies_index, mean_rating, dummie_idx_users, \n",
    "              dummie_idx_movies, N_dummies, dummie_idx_genre):\n",
    "    \n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = []\n",
    "    \n",
    "    for u,i in ids_to_estimate:\n",
    "        if u not in users_index and i in movies_index:\n",
    "            estimated.append(3)\n",
    "        \n",
    "        if u in users_index and i in movies_index:\n",
    "            x = get_x2(u,i,dummie_idx_users,dummie_idx_movies,dummie_idx_genre,N_dummies)\n",
    "            estimated.append(predict_f(x))\n",
    "            \n",
    "        if i not in movies_index:\n",
    "            estimated.append(mean_rating) # this is a new movie\n",
    "\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of clarity: the vector $x$ has his first $N users$ components used to map users, the following $N movies$ components, used to map movies and the last $N genre$ components, used to map movie genre.\n",
    "\n",
    "For example, observation 595384, is converted to this vector (we store in this case three more one for the genre):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  630570\n",
       "user_id                        999\n",
       "movie_id                      5377\n",
       "rating                           2\n",
       "title           About a Boy (2002)\n",
       "genre         Comedy|Drama|Romance\n",
       "Name: 595384, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[595384,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 953, 5308, 9787, 9790, 9797], dtype=int32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = get_x2(999, 5377, recog.dummie_idx_users, recog.dummie_idx_movies, recog.dummie_idx_genre, recog.N_dummies)\n",
    "x2.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecSys_fm5():\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "\n",
    "    def __init__(self, df_train, df_val, idx2genre=idx2genre, movie2genre=movie2genre, num_components=5):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.df_train       = df_train\n",
    "        self.df_val         = df_val\n",
    "        self.num_components = num_components\n",
    "        # We create a dictionary where we will store the user_id and movie_id which correspond \n",
    "        # to each index in the Rating matrix\n",
    "        self.N_samples = len(self.df_train)\n",
    "        self.users_index  = set(self.df_train.user_id)\n",
    "        self.movies_index = set(self.df_train.movie_id)\n",
    "        self.N_users      = len(self.users_index) \n",
    "        self.N_movies     = len(self.movies_index)\n",
    "        self.N_genre      = len(idx2genre)\n",
    "        self.N_dummies = self.N_users + self.N_movies + self.N_genre  \n",
    "        self.dummie_idx_users  = dict(zip(self.users_index, range(self.N_users)))\n",
    "        self.dummie_idx_movies = dict(zip(self.movies_index, range(self.N_users,self.N_users+self.N_movies)))\n",
    "        self.dummie_idx_genre  = dict(zip(movie2genre.keys(), [movie2genre[i] + self.N_users + self.N_movies for i in movie2genre.keys()]))\n",
    "\n",
    "                        \n",
    "        \n",
    "    def __sdg__(self):\n",
    "        l = []\n",
    "        for idx in self.training_indices:\n",
    "            l.append(idx)\n",
    "            if len(l)%1000 == 0: print('Wait {} idxs'.format(len(self.training_indices)-len(l)))\n",
    "            y     = np.array(self.df_train.iloc[idx,3]) \n",
    "            user  = self.df_train.iloc[idx,:].user_id\n",
    "            movie = self.df_train.iloc[idx,:].movie_id\n",
    "            x     = get_x2(user, movie, self.dummie_idx_users, self.dummie_idx_movies, self.dummie_idx_genre, self.N_dummies)\n",
    "            \n",
    "            prediction = self.predict(x)\n",
    "            loss_derivative = 2*(prediction-y)\n",
    "            #Update w0\n",
    "            grad_w0 = loss_derivative\n",
    "            self.w0 = self.w0 - self.learn_rate * (grad_w0 + 2*self.lmbda * self.w0)\n",
    "\n",
    "            for i in x.indices:\n",
    "                grad_w = loss_derivative * x[0,i]\n",
    "                self.w[i] = self.w[i] - self.learn_rate*(grad_w + 2*self.lmbda*self.w[i])\n",
    "\n",
    "                for f in range(self.num_components):\n",
    "                    grad_V = loss_derivative*x[0,i]*(sum(x*self.V[:, f]) - x[0,i]*self.V[i, f])\n",
    "                    self.V[i, f] = self.V[i, f] - self.learn_rate * (grad_V + 2*self.lmbda*self.V[i, f])\n",
    "            \n",
    "    def fit(self,n_epochs = 5,learning_rate =0.01,lmbda=0.1,verbose =True):\n",
    "        \"\"\" We decompose the R matrix into to submatrices using the training data \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.learn_rate = learning_rate\n",
    "        self.lmbda = lmbda\n",
    "        \n",
    "        self.mean_rating = self.df_train.rating.mean() \n",
    "        self.train_rmse =[]\n",
    "        self.test_rmse = []\n",
    "        iter_diff = 0\n",
    "        \n",
    "        # initialize model parameters\n",
    "        self.w0 = self.mean_rating\n",
    "        self.w  = np.random.normal(scale=1./self.N_dummies, size=self.N_dummies)\n",
    "        self.V  = np.random.normal(scale=1./self.num_components, size=(self.N_dummies, self.num_components))\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            print('Epoch: {}'.format(epoch))\n",
    "            \n",
    "            self.training_indices = np.arange(self.N_samples)\n",
    "            \n",
    "            #shuffle training samples\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            self.__sdg__()\n",
    "            \n",
    "            self.train_rmse.append(evaluate3(self.predict,self.df_train, self.users_index, self.movies_index, self.mean_rating, self.dummie_idx_users, self.dummie_idx_movies,self.N_dummies, self.dummie_idx_genre))\n",
    "            self.test_rmse.append(evaluate3(self.predict,self.df_val, self.users_index, self.movies_index, self.mean_rating, self.dummie_idx_users, self.dummie_idx_movies,self.N_dummies, self.dummie_idx_genre))\n",
    "            \n",
    "            print('\\tTrain rmse: %s' % self.train_rmse[-1])\n",
    "            print('\\tTest rmse: %s' % self.test_rmse[-1])\n",
    "            \n",
    "        if(self.verbose):\n",
    "            self.__plot_learning_curves__()\n",
    "    \n",
    "    def __plot_learning_curves__(self):\n",
    "        plt.plot(self.train_rmse,'--o',label=\"train_error\")\n",
    "        plt.plot(self.test_rmse,'--o',label=\"test_error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\" Single user and item prediction.\"\"\"\n",
    "        sx = 0 ; dx = 0 ; linear = 0\n",
    "        \n",
    "        for i in x.indices:\n",
    "            sx += self.V[i,:]*x[0,i]\n",
    "            dx += (self.V[i,:]**2)*x[0,i]**2\n",
    "            linear += self.w[i]*x[0,i]\n",
    "    \n",
    "        interact  = sum(sx**2 - dx)/2 \n",
    "\n",
    "        return self.w0 + linear + interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_red = df_train[df_train.user_id < 1000] \n",
    "df_val_red = df_val[df_val.user_id < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "recog = RecSys_fm5(df_train_red,df_val_red,num_components=5)\n",
    "#recog.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
